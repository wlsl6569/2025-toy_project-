'''
이진 분류, 로지스틱 회귀에서 널리 사용하는 손실함수로 아래와 같은 식을 사용한다.
BCE(p,y)=−[ylog(p)+(1−y)log(1−p)]

p는 모델의 예측 확률이고
y는 정답 라벨이다.

================배경 지식: likelihood ==========================

ML에서 우도 : 내 모델이 정답 y를 맞출 확률로 학습하며 점점 만들어져간다.
            이 값이 클수록 모델이 좋음 => 그래서 우도를 최대화하는 방향으로 학습함

# 데이터 하나짜리에서 likelihood

# 여러 데이터에서의 likelihood

# 로그 likelihood

# 음의 likelihood



======================= 수식 전개 =============================

y = 0 일때

−log(p)
'''